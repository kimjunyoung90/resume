
# 김준영 경력기술서

<div style="display: flex; align-items: flex-start; gap: 30px; margin-top: 20px;">
	<div style="flex: 1;">
		<img src="https://kimjunyoung90.github.io/resume/images/profile.png" alt="프로필" width="200"/>
	</div>
	<div style="flex: 2;">
		<h3>Contact</h3>
		<p>
			✉️ wnsdud1900427@gmail.com<br>
			<img src="https://kimjunyoung90.github.io/resume/images/github-mark.png" width="16" style="vertical-align: middle;"/> <a href="https://github.com/kimjunyoung90">https://github.com/kimjunyoung90</a><br>
			📝 <a href="https://snvlqkq.tistory.com">https://snvlqkq.tistory.com</a><br><br>
			<strong>GitHub:</strong> 동시성 처리 전략 및 오픈 소스 개발<br>
			<strong>Blog:</strong> SQL 튜닝 가이드 및 캐싱 처리 전략
		</p>
	</div>
</div>

# My Working Style

- **AI 도구를 활용해 업무 효율성을 높입니다.** 

    MCP 연동 등으로 AI를 업무 전반에 활용하여 Jira 이슈 관리, Wiki 문서 정리, 로그 분석, 코드 리뷰 등 반복 업무를 자동화하고 전체적인 생산성과 품질을 향상시킵니다.
    
- **업무의 우선순위를 지속적으로 재조정하며 핵심 목표에 집중합니다.** 

    매일·매주 업무 현황을 점검하고, 신규 개발·기능 개선·문의 대응 등 업무의 우선순위를 재조정합니다. 이를 통해 가장 주요한 일에 자원을 집중하여 높은 성과를 달성합니다.
    
- **이해하기 쉬운 커뮤니케이션으로 협업 효율을 높입니다.** 

    기술적인 내용을 비즈니스 언어로 풀어 기획자나 다른 서비스 개발자도 이해할 수 있도록 설명합니다. 시스템 흐름이나 업무 진행 현황 등 Mermaid 다이어그램과 Wiki 문서로 작성하여, 복잡한 이슈도 한눈에 파악할 수 있게 합니다.
    

---

# Skills

|분야|기술 스택|
|---|---|
|Backend|`Java`, `Spring`, `MyBatis`|
|DB|`PostgreSQL`, `Oracle`, `Redis`|
|Frontend|`JavaScript`, `React`, `Redux`, `Redux-Saga`|
|DevOps|`Jenkins`, `ELK`, `APM`|
|협업/관리|`Jira`, `Confluence`, `Git`|

---

# Work Experience

## 더존비즈온 WEHAGO 개발센터 (4년차)

2021.09 ~ 재직중

- HAProxy + 멀티 서버 구조의 고가용성 시스템 설계·운영
- Saga 패턴 기반 MSA 분산 트랜잭션 설계 및 구현
- 서킷 브레이커를 통한 분산 시스템간 장애 격리 흐름 구현
- RESTful API 설계·구현 및 JUnit/Mockito 기반 테스트 코드 작성
- 시스템 모니터링 및 성능 분석을 통한 병목지점 파악 및 개선
- 캐싱, 테이블 파티셔닝 관리, 인덱스 설계, 쿼리 튜닝 등을 통한 데이터 처리 성능 개선
- React 컴포넌트 개발 및 Redux 기반 상태 관리 적용

---

# Projects

## 전자세금계산서 서비스 운영 및 유지보수 (2021.09 ~ 현재)

- 월 6,500만 건, 최대 1,200 TPS 트래픽을 처리하는 세금계산서 발행·신고 및 전자문서 플랫폼 운영

### 대량 지연 대응 및 병목 해소

#### 문제
- 국세청 신고 기간 중 특정 API p95 응답시간이 25초까지 상승
- CPU·Memory·DB 등 주요 리소스는 정상 -> 애플리케이션 내부 병목 의심

#### 해결 전략
1) Thread Dump 기반 원인 분석
- 지연 시간대 Thread Dump 확보 및 분석
- 다수 스레드가 BLOCKED 상태로 대기 중인 현상 발견
- 세금계산서 발행 메서드 부분에 `synchronized` 키워드 확인

2) 단기 대응
- synchronized 제거의 안정성 검증 전까지 서버 scale-out(8 → 12대)으로 임시 처리량 확보
- 신고 기간 중 서비스 중단 없이 지연 문제를 빠르게 완화

3) 근본 원인 검증 및 해소
- 서버 내 synchronized로 영향받는 공유 자원 확인
- ExecutorService 기반 동시성 테스트 코드 작성, 시나리오별 검증
- JMeter로 부하 테스트 수행하여 추가 안정성 확인

4) 최종 조치
- 불필요한 synchronized 제거 및 배포
- 임시로 확대한 서버 수를 정상 규모로 원복

#### 성과
- 급격한 트래픽 증가에 신속히 대응하여 서비스 안정적인 운영 유지
- Thread Dump 분석을 통해 병목 구간을 정확히 식별하고 원인 제거
- TPS 3 → 25(8배 향상)

### 세금계산서 중복 발행 방지 기능 고도화

#### 문제
- 고객사의 비정상 요청(중복 요청·응답 미수신 재시도 등)으로 동일 세금계산서가 중복 발행되는 문제 발생
- 멱등성 보장을 위해 멱등키를 받고 있었으나 멱등키 NULL 허용, UNIQUE 제약조건 부재로 멱등성 보장 불가
- 테이블에 중복된 멱등키가 다수 존재 하여 제약조건을 추가하기 어려운 환경

#### 해결 전략
1) 멱등키 전용 테이블 신규 설계
- 기존 세금계산서 테이블의 정합성 문제를 우회하기 위해 멱등키만 관리하는 독립 테이블 신규 구축
- 기존 테이블 수정 없이도 멱등성 보장을 위한 분리 적용

2) 고객별 멱등키 충돌 방지를 위한 복합 Primary Key 적용
- PK 구성: (고객 고유번호, 멱등키 값)
- 고객 단위로 멱등키가 고유하도록 보장
- 동일 고객의 동일 멱등키 요청은 PK 충돌로 즉시 차단하여 중복 발행 근본 해결

3) 멱등성 보장 로직 구현 (DB 기반 처리 흐름)
- 멱등키 존재 시 멱등키 테이블에 INSERT 시도
- 이미 존재하는 경우 PK 충돌(duplicate key)로 중복 요청 즉시 감지
- 중복 발행 응답 반환

4) 멱등키 미전달 고객을 위한 호환성 처리
- 멱등키 미전달 고객은 멱등키 로직을 우회하도록 분기
- 기존 고객 영향도 최소화

#### 성과
- 동일 세금계산서 중복 발행 문제를 전면 차단, API 신뢰도 개선
- 기존 API 사용 고객의 호환성을 유지하면서도 새로운 멱등성 보장 구조 적용
- NULL·중복 멱등키가 포함된 기존 데이터 수정 없이 적용 가능하여 운영 리스크 최소화

### 분산 트랜잭션 정합성 확보 (Saga Orchestration)

#### 문제
- 세금계산서 발행 프로세스는 포인트 시스템과 연계되어 포인트 차감 → 세금계산서 발행 → (실패 시) 포인트 환불 순으로 진행
- 기존에는 문서 발행 실패 시 단순 보상 트랜잭션 API 호출에 의존하여, 보상 실패 시 데이터 정합성을 회복할 메커니즘이 부재
- 포인트는 차감되었으나 문서는 발행되지 않는 심각한 정합성 오류 발생

#### 해결 전략
1) 보상 결과 영속화
- 보상 트랜잭션 실패 이력을 저장하는 전용 테이블 생성
- 문서 번호(멱등키), 상태(READY, FAIL, RETRY, SUCCESS), 재처리 횟수, 환불 포인트, 사용자 고유 번호로 구성
- 보상 트랜잭션 실패 시 실패 이력 적재

2) 보상 트랜잭션 재처리 체계 구축
- Scheduler를 활용해 실패 트랜잭션을 주기적으로 조회하여 환불 API 비동기 호출
- 최대 재시도 횟수 제한으로 무한 재시도 방지
- 최종 실패 시 백오피스에서 수동 복구 기능 제공

3) DB 부하 최소화
- (상태 + 인입 시간) 복합 인덱스 생성
- 최대 100건 조회 제한으로 DB 부하 및 조회 성능 최적화

#### 성과
- **분산 트랜잭션 데이터 정합성 문제 해소**, 포인트·문서 데이터 불일치 사례 제거
- 보상 실패 시에도 복구 가능한 **재처리/복구 체계를 확보**하여 **시스템 안정성 강화**

### 무료 발행 이벤트 동시성 제어

#### 문제
- 신규 채권 발행 서비스 출시 프로모션으로 고객별 무료 발행 100건 이벤트 진행
- 무료 발행 건수 차감 시 SELECT 후 UPDATE로 인한 동시성 문제 발생

#### 해결 전략
1) 동시성 문제 재현 및 분석
- ExecutorService 기반 동시성 테스트 코드 작성하여 이슈 재현
- 10개 스레드풀 생성만으로도 동시성 이슈 발생 확인
- 단일 쿼리로 개선 검토했으나, 히스토리를 쌓아야 해서 로직 개선 불가

2) Optimistic Lock 적용
- 한 회사당 100건, 회사에 일반적으로 채권 발행 담당자가 소수이고 초기 서비스라 사용자가 적어 경합이 적을 것으로 판단
- 경합 확률이 낮은 구조를 고려해 Optimistic Lock + Spring Retry 적용
- version 컬럼을 추가하여 충돌 감지

3) 재시도 전략
- backoff, random, multiplier, maxDelay 설정 적용
- 경합 상황에서 모든 트랜잭션이 즉시 재시도를 수행하면 재경합 가능성이 높아 대기시간 지정(backoff)
- 재시도 시점을 랜덤하게 지정하여 동시 경합 가능성 완화(random)
- 재시도 횟수 증가 시 대기 시간을 점진적으로 증가시켜 경합 완화(multiplier)
- 임의로 재시도 설정 변경 시 지연이 무한정 길어지는 현상 방지(maxDelay)

4) 최종 실패 처리
- 최종 재시도 실패 시 recover 메서드를 실행하여 실패 응답 반환 및 로그 적재
- 비관적 락으로의 전환 시점 파악

#### 성과
- 발행 동시 요청 상황에서도 중복 차감 이슈 없이 안정적으로 처리
- Optimistic Lock 기반의 효율적 동시성 제어 구조 구현

---

## 의료마이데이터 신규 서비스 개발 (2024.05 ~ 2024.07)

- 공공기관에 분산된 개인 의료 데이터를 수집하여 통합 관리하는 건강정보 플랫폼 개발

### 외부 시스템 장애 격리 구현

#### 문제
- 의료마이데이터 서비스는 고객의 진료 기록·건강 검진 결과·처방 기록을 사내 데이터 수집 시스템에서 조회해 제공하는 구조
- 데이터 수집 시스템에서 지연 또는 간헐적 장애가 발생하면 의료마이데이터 전체 서비스의 응답이 지연되고, 톰캣 워커 스레드의 고갈 우려

#### 해결 전략
- Spring 4.3 기술 스택과 호환이 좋은 Hystrix Circuit Breaker 적용
- 도메인별(진료, 검진, 의료기록 등) 스레드풀 격리 및 큐 용량 제한(10)
- 실패율 50% 이상 시 회로 차단(Open), 10초 후 Half-Open 전환
- 설정값을 30초 주기로 재로드하여 회로 차단 임계값과 타임아웃 등이 실시간으로 변경되도록 적용
- 회로 차단 시 "일시적 조회 불가" 대체 응답 제공

#### 성과
- 톰캣 워커 스레드 고갈 방지 및 장애 전파 차단
- 외부 의존도가 높은 구조에서도 안정적인 서비스 구축

---

## 뉴스 데이터 수집 시스템 개선 (2024.03)

- 언론사의 기사 데이터를 수집·가공·조회하는 서비스 구조 개선

### 구조적 문제 해결

#### 문제
- 단일 신문사에 맞춰 설계된 DB 구조로 인해 신규 언론사 추가 시 확장성 제한
- 기존 구조는 publisher_categories(신문사 카테고리) 데이터를 UI에 직접 노출하는 방식이며 뉴스 컨텐츠는 자신이 어느 신문사의 카테고리에 속하는지 저장하고 있는 형태
- 단일 신문사에서는 문제가 없었지만, 카테고리를 추가하면 UI에 무분별하게 카테고리가 노출되고, 카테고리를 수정하면 기존 뉴스 데이터의 매핑 정보를 모두 변경해야 하는 문제 발생

#### 해결 전략
1) 플랫폼 표준 카테고리 기반 DB 구조 재설계
- 정치·경제·사회·IT·문화 등 플랫폼 전용 카테고리를 정의한 `platform_categories` 테이블 신설
- 언론사별 카테고리(`publisher_categories`)를 플랫폼 표준 카테고리에 매핑하는 `category_mapping` 테이블 설계
- 신규 언론사 추가 시 매핑 데이터만 등록하면 확장 가능하도록 설계
- 플랫폼 카테고리에 변경 시에도 매핑 데이터 수정만으로 신문사의 다른 카테고리 뉴스를 조회 가능하도록 설계

2) 캐시 계층 도입
- 카테고리 조회 시점에 `category_mapping`을 참조하여 플랫폼 표준 카테고리 기준으로 `publisher_categories` 조회
- 카테고리 정보는 자주 변경되지 않지만 지속적으로 데이터베이스를 조회해야하는 문제 발생
- Redis 기반 캐시 계층을 도입해 카테고리 조회 시마다 JOIN이 반복되면서 DB 부하가 증가하던 문제를 해결

3) 전략패턴 기반 기사 수집 프로세스 공통화
- 언론사별 데이터 수집 및 파싱 로직을 전략 패턴을 사용하여 공통 NewsCollector 인터페이스로 통합
- 신규 언론사 추가 시 비즈니스 로직을 수정할 필요 없이 전략 클래스만 추가하면 확장이 가능하도록 설계

#### 성과

- 신규 언론사 연동 및 표준 카테고리 변경 시 데이터만으로 즉시 반영 가능
- 수집·조회 로직 공통화로 신규 제휴 추가 시 개발 공수 절감
- Redis 캐시 적용으로 조회 시 JOIN 부하 제거 및 응답 속도 개선

---

# Certifications

- **정보처리기사** _(2023.09)_
- **SQLD** _(2022.06)_
- **네트워크 관리사 2급** _(2022.04)_
