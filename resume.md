
# 김준영 경력기술서

<div style="display: flex; align-items: flex-start; gap: 30px; margin-top: 20px;">
	<div style="flex: 1;">
		<img src="https://kimjunyoung90.github.io/resume/images/profile.png" alt="프로필" width="200"/>
	</div>
	<div style="flex: 2;">
		<h3>Contact</h3>
		<p>
			✉️ wnsdud1900427@gmail.com<br>
			<img src="https://kimjunyoung90.github.io/resume/images/github-mark.png" width="16" style="vertical-align: middle;"/> <a href="https://github.com/kimjunyoung90">https://github.com/kimjunyoung90</a><br>
			📝 <a href="https://snvlqkq.tistory.com">https://snvlqkq.tistory.com</a><br><br>
			<strong>GitHub:</strong> <a href="https://github.com/kimjunyoung90/concurrency-examples">동시성 처리 전략</a> 및 <a href="https://www.npmjs.com/package/global-message-converter">오픈 소스 개발</a><br>
			<strong>Blog:</strong> <a href="https://snvlqkq.tistory.com/29">SQL 인덱스 미사용 안티 쿼리 패턴</a> 및 <a href="https://snvlqkq.tistory.com/25">캐싱 처리 전략</a>
		</p>
	</div>
</div>

# My Working Style

- **AI 도구를 활용해 업무 효율성을 높입니다.** 

    Confluence Wiki에 API 명세를 수작업으로 작성하던 과정을 AI와 MCP로 자동화하고, 적용 및 연동 방법을 정리한 가이드 문서를 작성해 공유하여 조직 전체의 생산성을 높였습니다.
    
- **반복되는 개발 과정의 비효율을 주도적으로 개선합니다.**

	다국적 서비스 제공하기 위해 수행했던 반복작업을 자동화하여 5분 이내로 단축했고, 이를 오픈소스로 배포해 내부뿐 아니라 외부 개발자들도 자동으로 다국적 서비스를 빠르게 제공할 수 있도록 기여했습니다.
    
- **이해하기 쉬운 커뮤니케이션으로 협업 효율을 높입니다.** 

    기술적인 내용을 비즈니스 언어로 풀어 기획자나 다른 서비스 개발자도 이해할 수 있도록 설명합니다. 시스템 흐름이나 업무 진행 현황을 Mermaid 다이어그램과 Wiki 문서로 작성하여, 복잡한 이슈도 한눈에 파악할 수 있게 합니다.
    

---

# Skills

|분야|기술 스택|
|---|---|
|Backend|`Java`, `Spring Framework`, `MyBatis`|
|DB|`Oracle`, `PostgreSQL`, `Redis`|
|Frontend|`JavaScript`, `React`, `Redux`, `Redux-Saga`|
|DevOps|`Jenkins`, `ELK`, `APM`|
|협업/관리|`Jira`, `Confluence`, `Git`|

---

# Work Experience

## 더존비즈온 WEHAGO 개발센터 (4년차)

2021.09 ~ 재직중

- HAProxy + 서버 이중화 구조의 고가용성 시스템 설계·운영
- RESTful API 설계·구현 및 JUnit/Mockito 기반 테스트 코드 작성
- MSA 분산 트랜잭션 Saga 패턴 설계 및 구현
- 시스템 모니터링 및 성능 분석을 통한 병목지점 파악 및 개선
- 캐싱, 인덱스 설계, 쿼리 튜닝 등을 통한 데이터 처리 성능 개선
- React 컴포넌트 개발 및 Redux 기반 상태 관리 적용

---

# Projects

## 전자세금계산서 서비스 운영 및 유지보수 (2021.09 ~ 현재)

- 월 6,500만 건, 최대 1,200 TPS 트래픽을 처리하는 세금계산서 발행·신고 및 전자문서 플랫폼 운영

### API 지연 해결

#### 문제
- 트래픽 집중 기간(월 1~10일) 요청량 급증으로 대량 API 지연 발생
- Elastic APM에서 latency 증가·throughput 감소 현상 관측
- DB 및 외부 호출 구간은 정상 응답 → 애플리케이션 내부 처리 병목으로 판단

#### 해결 전략
**1) Thread 상태 분석을 통한 원인 특정**
- 외부 호출/DB 지연이 없었기 때문에 Thread 상태를 우선 확인
- jstack 기반 Thread Dump 분석 과정에서 BLOCKED 스레드 대량 포착
- Stack Trace를 통해 공통적으로 Blocking이 발생하는 메서드 특정
- 코드 레벨 검토 결과, 해당 메서드가 `synchronized`에 의해 직렬 처리되고 있음을 발견
- synchronized가 보호하려던 공유 자원이 없고, 멀티 인스턴스 환경에서는 실효성이 없다고 판단하여 키워드 제거 결정

**2) 부하 테스트를 통한 개선 효과 검증**
- staging 환경 부재로 개발 환경에서 부하 테스트 수행
- 절대 수치보다는 synchronized 제거 전/후 비교에 중점
- JMeter 기반 검증 결과, 제거 이후 latency 감소 및 throughput 증가 확인

**3) 운영 적용 및 지속적 모니터링**
- 개선사항 운영 반영 후 Elastic APM과 Thread 상태 지속 모니터링
- 월초 피크 구간에서도 동시성 병목이 재발하지 않는 것을 확인

**4) 팀 공유를 통한 재발 방지**
- synchronized 사용 시 병목 위험, 제거 과정, 개선 지표 등을 Wiki 문서화
- 구성원 대상으로 동시성 제어 베스트 프랙티스 공유

#### 성과
- synchronized 제거 이후 월초 피크 구간에서도 latency 지표가 안정적으로 유지
- Thread Dump 상 BLOCKED 스레드가 재발하지 않았으며, 동일한 성능 이슈 근절

### API 멱등성 개선

#### 문제
- 고객사의 비정상 요청(중복 요청·응답 미수신)으로 동일 세금계산서가 간헐적으로 중복 발행
- 기존 구조 : 멱등키 NULL 허용 및 UNIQUE 제약 부재로 동시성 환경에서 멱등성 보장 실패
- 중복 적재된 멱등키, 히스토리 파악 불가로 기존 테이블 수정 불가 및 기능 연동 시스템 호환성 유지 필요

#### 해결 전략
1) 멱등키 전용 테이블 신규 설계
- 기존 세금계산서 테이블의 정합성 문제를 우회하기 위해 멱등키만 관리하는 독립 테이블 신규 구축
- 기존 테이블 수정 없이도 멱등성 보장을 위한 분리 적용

2) 고객별 멱등키 충돌 방지를 위한 복합 Primary Key 적용
- PK 구성: (고객 고유번호, 멱등키 값)
- 고객 단위로 멱등키가 고유하도록 보장
- 동일 고객의 동일 멱등키 요청은 PK 충돌로 즉시 차단하여 중복 발행 근본 해결

3) 멱등성 보장 로직 구현 (DB 기반 처리 흐름)
- 멱등키 존재 시 멱등키 테이블에 INSERT 시도
- 이미 존재하는 경우 PK 충돌(duplicate key)로 중복 요청 즉시 감지
- 중복 발행 응답 반환

4) 멱등키 미전달 고객을 위한 호환성 처리
- 멱등키 미전달 고객은 멱등키 로직을 우회하도록 분기
- 기존 고객 영향도 최소화

#### 성과
- 동일 세금계산서 중복 발행 문제를 전면 차단, API 신뢰도 개선
- API 사용 고객의 호환성을 유지하면서도 멱등성 개선

### 분산 시스템간 트랜잭션 정합성 개선

#### 문제
- 세금계산서 발행 프로세스는 포인트 시스템과 연계되어 포인트 차감 → 세금계산서 발행 → (실패 시) 포인트 환불 순으로 진행
- 기존에는 보상 실패 시 데이터 정합성을 회복할 메커니즘이 부재
- 결과적으로 문서는 발행되지 않았으나 포인트가 환불되지 않는 정합성 오류 발생

#### 해결 전략
1) 보상 결과 영속화
- 보상 트랜잭션 실패 이력을 저장하는 전용 테이블 생성
- 문서 번호(멱등키), 상태(READY, FAIL, RETRY, SUCCESS), 재처리 횟수, 환불 포인트, 사용자 고유 번호로 구성
- 보상 트랜잭션 실패 시 실패 이력 적재

2) 보상 트랜잭션 재처리 체계 구축
- Scheduler를 활용해 실패 트랜잭션을 주기적으로 조회하여 환불 API 호출
- 최대 재시도 횟수 제한으로 무한 재시도 방지
- 최종 실패 시 백오피스에서 수동 복구 기능 제공

3) DB 부하 최소화
- (상태 + 인입 시간) 복합 인덱스 생성
- 최대 100건 조회 제한으로 DB 부하 및 조회 성능 최적화

#### 성과
- **분산 트랜잭션 데이터 정합성 문제 해소**, 포인트·문서 데이터 불일치 사례 제거
- 보상 실패 시에도 복구 가능한 **재처리/복구 체계를 확보**하여 **시스템 안정성 강화**

### 무료 발행 이벤트 동시성 제어

#### 문제
- 신규 채권 발행 서비스 출시 프로모션으로 고객별 무료 발행 100건 이벤트 진행
- 무료 발행 건수 차감 시 SELECT 후 UPDATE로 인한 동시성 문제 발생

#### 해결 전략
1) 동시성 문제 재현 및 분석
- ExecutorService 기반 동시성 테스트 코드 작성하여 이슈 재현
- 10개 스레드풀 생성만으로도 동시성 이슈 발생 확인
- 단일 쿼리로 개선 검토했으나, 히스토리를 쌓아야 해서 로직 개선 불가

2) Optimistic Lock 적용
- 한 회사당 100건, 회사에 일반적으로 채권 발행 담당자가 소수이고 초기 서비스라 사용자가 적어 경합이 적을 것으로 판단
- 경합 확률이 낮은 구조를 고려해 Optimistic Lock + Spring Retry 적용
- version 컬럼을 추가하여 충돌 감지

3) 재시도 전략
- backoff, random, multiplier, maxDelay 설정 적용
- 경합 상황에서 모든 트랜잭션이 즉시 재시도를 수행하면 재경합 가능성이 높아 대기시간 지정(backoff)
- 재시도 시점을 랜덤하게 지정하여 동시 경합 가능성 완화(random)
- 재시도 횟수 증가 시 대기 시간을 점진적으로 증가시켜 경합 완화(multiplier)
- 임의로 재시도 설정 변경 시 지연이 무한정 길어지는 현상 방지(maxDelay)

4) 최종 실패 처리
- 최종 재시도 실패 시 recover 메서드를 실행하여 실패 응답 반환 및 로그 적재
- 비관적 락으로의 전환 시점 파악

#### 성과
- 발행 동시 요청 상황에서도 중복 차감 이슈 없이 안정적으로 처리
- Optimistic Lock 기반의 효율적 동시성 제어 구조 구현

---

## 뉴스 데이터 수집 시스템 개선 (2024.03)

- 언론사의 기사 데이터를 수집·가공·조회하는 서비스 구조 개선

### 구조적 문제 해결

#### 문제
- 단일 신문사에 맞춰 설계된 DB 구조로 인해 신규 언론사 추가 시 확장성 제한
- 기존 구조는 publisher_categories(신문사 카테고리) 데이터를 UI에 직접 노출하는 방식이며 뉴스 컨텐츠는 자신이 어느 신문사의 카테고리에 속하는지 저장하고 있는 형태
- 단일 신문사에서는 문제가 없었지만, 카테고리를 추가하면 UI에 무분별하게 카테고리가 노출되고, 카테고리를 수정하면 기존 뉴스 데이터의 매핑 정보를 모두 변경해야 하는 문제 발생

#### 해결 전략
1) 플랫폼 표준 카테고리 기반 DB 구조 재설계
- 정치·경제·사회·IT·문화 등 플랫폼 전용 카테고리를 정의한 `platform_categories` 테이블 신설
- 언론사별 카테고리(`publisher_categories`)를 플랫폼 표준 카테고리에 매핑하는 `category_mapping` 테이블 설계
- 신규 언론사 추가 시 매핑 데이터만 등록하면 확장 가능하도록 설계
- 플랫폼 카테고리에 변경 시에도 매핑 데이터 수정만으로 신문사의 다른 카테고리 뉴스를 조회 가능하도록 설계

2) 캐시 계층 도입
- 카테고리 조회 시점에 `category_mapping`을 참조하여 플랫폼 표준 카테고리 기준으로 `publisher_categories` 조회
- 카테고리 정보는 자주 변경되지 않지만 지속적으로 데이터베이스를 조회해야하는 문제 발생
- Redis 기반 캐시 계층을 도입해 카테고리 조회 시마다 JOIN이 반복되면서 DB 부하가 증가하던 문제를 해결

3) 전략패턴 기반 기사 수집 프로세스 공통화
- 언론사별 데이터 수집 및 파싱 로직을 전략 패턴을 사용하여 공통 NewsCollector 인터페이스로 통합
- 신규 언론사 추가 시 비즈니스 로직을 수정할 필요 없이 전략 클래스만 추가하면 확장이 가능하도록 설계

#### 성과

- 신규 언론사 연동 및 표준 카테고리 변경 시 데이터만으로 즉시 반영 가능
- 수집·조회 로직 공통화로 신규 제휴 추가 시 개발 공수 절감
- Redis 캐시 적용으로 조회 시 JOIN 부하 제거 및 응답 속도 개선

---

## 업무 생산성 개선

### API 명세 자동화 (2025)

#### 문제
- 신규 API 개발 후 Confluence Wiki에 명세서를 수작업으로 작성해야 했음
- 작성 누락 발생 및 문서화에 시간이 소요되어 개발 집중도 저하

#### 해결 전략
- MCP 공식 Agent가 구축형 Confluence에서는 사용할 수 없는 제약을 해결하기 위해 커뮤니티 MCP 탐색 및 연동
- API 명세 자동 생성 기능 테스트 및 적용
- 적용 및 연동 방법을 가이드 문서로 정리하여 팀 전파

#### 성과
- 명세 작성 누락 감소 및 문서 일관성 확보
- 수작업 문서 작성 시간 절감, 개발 효율 증가
- 조직 전체에 자동화 적용 구조 확산

### 다국어 처리 자동화 CLI 개발 (2024)

#### 문제
- React 기반 다국어 적용 시 JSX, 속성, 함수 내 텍스트를 수작업으로 메시지 파일로 변환해야 함
- 반복 업무로 인해 개발 생산성이 저하되고 누락이 빈번하게 발생

#### 해결 전략
- babel parser 기반 AST 탐색을 통해 하드코딩된 문자열을 자동으로 추출해 메시지 키로 변환하는 CLI 개발
- npm 모듈 형태로 CLI 패키징하여 배포 (오픈소스 공개)

#### 성과
- 기존 수십 분~수 시간 소요되던 작업을 5분 이내로 단축
- 다국어 적용 반복 업무 대폭 감소로 개발자 생산성 향상
- 내부뿐 아니라 외부 개발자들도 사용 가능 (npm registry 공개)

---

# Certifications

- **정보처리기사** _(2023.09)_
- **SQLD** _(2022.06)_
- **네트워크 관리사 2급** _(2022.04)_
